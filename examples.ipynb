{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6982185,"sourceType":"datasetVersion","datasetId":4012665},{"sourceId":7659768,"sourceType":"datasetVersion","datasetId":4466132}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone -b ema https://github.com/edoppiap/bert_medical_records.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-21T21:48:40.141406Z","iopub.execute_input":"2024-02-21T21:48:40.141826Z","iopub.status.idle":"2024-02-21T21:48:41.666997Z","shell.execute_reply.started":"2024-02-21T21:48:40.141792Z","shell.execute_reply":"2024-02-21T21:48:41.665844Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Cloning into 'bert_medical_records'...\nremote: Enumerating objects: 305, done.\u001b[K\nremote: Counting objects: 100% (111/111), done.\u001b[K\nremote: Compressing objects: 100% (78/78), done.\u001b[K\nremote: Total 305 (delta 62), reused 66 (delta 31), pack-reused 194\u001b[K\nReceiving objects: 100% (305/305), 194.18 KiB | 10.79 MiB/s, done.\nResolving deltas: 100% (181/181), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -r bert_medical_records/requirements.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python /kaggle/working/bert_medical_records/preprocessing_python/text_generator.py \\\n        --file_path /kaggle/input/base-ehr-data/base_red3.csv \\\n        --output_folder /kaggle/working \\\n        --create_pretrain_text_file","metadata":{"execution":{"iopub.status.busy":"2024-02-21T20:21:08.583647Z","iopub.execute_input":"2024-02-21T20:21:08.584008Z","iopub.status.idle":"2024-02-21T20:21:12.570267Z","shell.execute_reply.started":"2024-02-21T20:21:08.583974Z","shell.execute_reply":"2024-02-21T20:21:12.568963Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Producing text file from csv dataset: 100%|â–ˆâ–ˆ| 680/680 [00:01<00:00, 520.35it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!python bert_medical_records/run_pre_train.py \\\n      --do_eval \\\n      --do_train \\\n      --train_batch_size 10 \\\n      --pre_train_tasks mlm_nsp \\\n      --num_epochs 8 \\\n      --input_file /kaggle/working/dataset_text.txt \\\n      --use_pretrained_bert","metadata":{"execution":{"iopub.status.busy":"2024-02-21T20:21:12.571841Z","iopub.execute_input":"2024-02-21T20:21:12.572190Z","iopub.status.idle":"2024-02-21T21:41:27.290770Z","shell.execute_reply.started":"2024-02-21T20:21:12.572157Z","shell.execute_reply":"2024-02-21T21:41:27.289648Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"2024-02-21 20:21:22.064820: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-21 20:21:22.064920: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-21 20:21:22.166690: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOutput files will be saved in folder: /kaggle/working/bert_medical_records/logs/21-02-2024_20-21\ntokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48.0/48.0 [00:00<00:00, 227kB/s]\nvocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:00<00:00, 62.1MB/s]\ntokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 466k/466k [00:00<00:00, 42.8MB/s]\nconfig.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 570/570 [00:00<00:00, 3.15MB/s]\nmodel.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 440M/440M [00:11<00:00, 39.9MB/s]\n  0%|                                                   | 0/865 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\nEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:32<00:00,  1.51it/s, loss=0.341]\nEpoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:33<00:00,  1.51it/s, loss=0.143]\nEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:33<00:00,  1.51it/s, loss=0.0444]\nEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:34<00:00,  1.51it/s, loss=0.0776]\nEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:34<00:00,  1.51it/s, loss=0.00435]\nEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:34<00:00,  1.51it/s, loss=0.51]\nEpoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:34<00:00,  1.51it/s, loss=0.069]\nEpoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:34<00:00,  1.51it/s, loss=0.0271]\nAverage loss = 0.02712048776447773\nEvaluating: 100%|â–ˆ| 217/217 [02:58<00:00,  1.22it/s, loss=tensor(0.0119, device=\nNsp acc: 0.9380203515263644\nMlm acc: 0.47597597597597596\n","output_type":"stream"}]},{"cell_type":"code","source":"!python /kaggle/working/bert_medical_records/run_glue.py \\\n      --do_train \\\n      --do_eval \\\n      --train_batch_size 10 \\\n      --num_epochs 1 \\\n      --model_input /kaggle/working/21-02-2024_20-21 \\\n      --input_file /kaggle/working/finetuning_dataset.txt","metadata":{"execution":{"iopub.status.busy":"2024-02-21T21:49:10.916140Z","iopub.execute_input":"2024-02-21T21:49:10.916526Z","iopub.status.idle":"2024-02-21T21:58:28.985664Z","shell.execute_reply.started":"2024-02-21T21:49:10.916495Z","shell.execute_reply":"2024-02-21T21:58:28.984534Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"2024-02-21 21:49:16.437804: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-21 21:49:16.437865: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-21 21:49:16.439356: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOutput files will be saved in folder: /kaggle/working/bert_medical_records/logs/21-02-2024_21-49\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/working/21-02-2024_20-21/pre_trained_model and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/kaggle/working/bert_medical_records/load_dataset.py:34: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3614.)\n  inputs['labels'] = torch.LongTensor(labels).T\nlen(train_dataset) = 9185\nlen(test_dataset) = 2296\n  0%|                                                   | 0/919 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\nEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 919/919 [08:16<00:00,  1.85it/s, loss=0.182]\nAverage loss = 0.18166837096214294\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:41<00:00,  5.57it/s, loss=64.2]\n1992\n/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:37: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:31: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\nresult = {'acc': 0.867595818815331, 'f1': 0.8983957219251336, 'acc_and_f1': 0.8829957703702322}\n","output_type":"stream"}]},{"cell_type":"code","source":"!python /kaggle/working/bert_medical_records/run_glue.py \\\n      --do_train \\\n      --do_eval \\\n      --train_batch_size 10 \\\n      --num_epochs 1 \\\n      --use_pretrained_bert \\\n      --input_file /kaggle/working/finetuning_dataset.txt","metadata":{"execution":{"iopub.status.busy":"2024-02-21T22:05:16.528046Z","iopub.execute_input":"2024-02-21T22:05:16.528807Z","iopub.status.idle":"2024-02-21T22:14:34.908908Z","shell.execute_reply.started":"2024-02-21T22:05:16.528758Z","shell.execute_reply":"2024-02-21T22:14:34.907952Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"2024-02-21 22:05:21.893813: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-21 22:05:21.893866: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-21 22:05:21.895286: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOutput files will be saved in folder: /kaggle/working/bert_medical_records/logs/21-02-2024_22-05\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/kaggle/working/bert_medical_records/load_dataset.py:34: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3614.)\n  inputs['labels'] = torch.LongTensor(labels).T\nlen(train_dataset) = 9185\nlen(test_dataset) = 2296\n  0%|                                                   | 0/919 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\nEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 919/919 [08:16<00:00,  1.85it/s, loss=0.589]\nAverage loss = 0.5890824198722839\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:41<00:00,  5.57it/s, loss=145]\n1564\n/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:37: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:31: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\nresult = {'acc': 0.681184668989547, 'f1': 0.8103626943005181, 'acc_and_f1': 0.7457736816450325}\n","output_type":"stream"}]},{"cell_type":"code","source":"!python bert_medical_records/run_pre_train.py \\\n      --do_eval \\\n      --do_train \\\n      --train_batch_size 10 \\\n      --pre_train_tasks mlm_nsp \\\n      --num_epochs 8 \\\n      --input_file /kaggle/working/dataset_text.txt ","metadata":{"execution":{"iopub.status.busy":"2024-02-21T22:25:33.522462Z","iopub.execute_input":"2024-02-21T22:25:33.523434Z","iopub.status.idle":"2024-02-21T23:45:01.646099Z","shell.execute_reply.started":"2024-02-21T22:25:33.523397Z","shell.execute_reply":"2024-02-21T23:45:01.644934Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"2024-02-21 22:25:39.484372: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-21 22:25:39.484429: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-21 22:25:39.485956: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOutput files will be saved in folder: /kaggle/working/bert_medical_records/logs/21-02-2024_22-25\nTrain the tokenizer\n\u001b[2K[00:00:00] Tokenize words                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 854      /      854[00:00:00] Tokenize words                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0        /        0\n\u001b[2K[00:00:00] Count pairs                    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 854      /      854\n\u001b[2K[00:00:00] Compute merges                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1248     /     1248\nSaving the tokenizer\nLoading the workable tokenizer\n  0%|                                                   | 0/865 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\nEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:31<00:00,  1.51it/s, loss=0.753]\nEpoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:32<00:00,  1.51it/s, loss=0.702]\nEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:33<00:00,  1.51it/s, loss=0.6]\nEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:33<00:00,  1.51it/s, loss=0.143]\nEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:34<00:00,  1.51it/s, loss=0.37]\nEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:34<00:00,  1.51it/s, loss=0.436]\nEpoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:34<00:00,  1.51it/s, loss=0.591]\nEpoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:33<00:00,  1.51it/s, loss=0.0535]\nAverage loss = 0.053481828421354294\nEvaluating: 100%|â–ˆ| 217/217 [02:40<00:00,  1.35it/s, loss=tensor(0.0339, device=\nNsp acc: 0.8714153561517114\nMlm acc: 0.03727714748784441\n","output_type":"stream"}]},{"cell_type":"code","source":"!python /kaggle/working/bert_medical_records/preprocessing_python/text_generator.py \\\n        --file_path /kaggle/input/base-ehr-data/base_red3.csv \\\n        --output_folder /kaggle/working \\\n        --output_name finetuning_dataset.txt \\\n        --create_finetuning_text_data","metadata":{"execution":{"iopub.status.busy":"2024-02-21T21:41:42.776628Z","iopub.execute_input":"2024-02-21T21:41:42.777539Z","iopub.status.idle":"2024-02-21T21:41:46.508423Z","shell.execute_reply.started":"2024-02-21T21:41:42.777501Z","shell.execute_reply":"2024-02-21T21:41:46.507344Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Reading input file: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680/680 [00:01<00:00, 446.37it/s]\nCreating dataset for finetuning: 11481it [00:00, 150686.72it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!python /kaggle/working/bert_medical_records/run_glue.py \\\n      --do_train \\\n      --do_eval \\\n      --train_batch_size 10 \\\n      --num_epochs 1 \\\n      --model_input /kaggle/working/bert_medical_records/logs/21-02-2024_22-25 \\\n      --input_file /kaggle/working/finetuning_dataset.txt","metadata":{"execution":{"iopub.status.busy":"2024-02-21T23:45:01.648181Z","iopub.execute_input":"2024-02-21T23:45:01.648497Z","iopub.status.idle":"2024-02-21T23:54:19.527014Z","shell.execute_reply.started":"2024-02-21T23:45:01.648466Z","shell.execute_reply":"2024-02-21T23:54:19.525893Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"2024-02-21 23:45:07.153865: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-21 23:45:07.153923: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-21 23:45:07.155501: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOutput files will be saved in folder: /kaggle/working/bert_medical_records/logs/21-02-2024_23-45\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/working/bert_medical_records/logs/21-02-2024_22-25/pre_trained_model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/kaggle/working/bert_medical_records/load_dataset.py:34: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3614.)\n  inputs['labels'] = torch.LongTensor(labels).T\nlen(train_dataset) = 9185\nlen(test_dataset) = 2296\n  0%|                                                   | 0/919 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\nEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 919/919 [08:16<00:00,  1.85it/s, loss=0.508]\nAverage loss = 0.5082177519798279\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:41<00:00,  5.55it/s, loss=142]\n1621\n/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:37: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:31: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\nresult = {'acc': 0.7060104529616724, 'f1': 0.8209074024940303, 'acc_and_f1': 0.7634589277278514}\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\n\n# Specify the path to the folder you want to zip\nfolder_path = '/kaggle/working/bert_medical_records/logs'\n\n# Specify the path for the resulting zip file\nzip_file_path = '/kaggle/working/logs'\n\n# Create a zip file\nshutil.make_archive(zip_file_path, 'zip', folder_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T00:01:02.662625Z","iopub.execute_input":"2024-02-22T00:01:02.663393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !cp -r /kaggle/working/bert_medical_records/logs/21-02-2024_20-21 /kaggle/working/21-02-2024_20-21","metadata":{"execution":{"iopub.status.busy":"2024-02-21T21:44:35.647840Z","iopub.execute_input":"2024-02-21T21:44:35.648211Z","iopub.status.idle":"2024-02-21T21:44:36.987995Z","shell.execute_reply.started":"2024-02-21T21:44:35.648179Z","shell.execute_reply":"2024-02-21T21:44:36.986694Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# !rm -r bert_medical_records","metadata":{"execution":{"iopub.status.busy":"2024-02-21T21:48:35.620442Z","iopub.execute_input":"2024-02-21T21:48:35.621078Z","iopub.status.idle":"2024-02-21T21:48:36.623777Z","shell.execute_reply.started":"2024-02-21T21:48:35.621047Z","shell.execute_reply":"2024-02-21T21:48:36.622299Z"},"trusted":true},"execution_count":12,"outputs":[]}]}