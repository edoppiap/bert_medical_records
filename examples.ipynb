{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e84fe47",
   "metadata": {
    "papermill": {
     "duration": 0.012845,
     "end_time": "2024-02-25T17:08:38.628641",
     "exception": false,
     "start_time": "2024-02-25T17:08:38.615796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create pre-train and finetuning dataset text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64c3d1c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T17:08:38.657918Z",
     "iopub.status.busy": "2024-02-25T17:08:38.657047Z",
     "iopub.status.idle": "2024-02-25T17:08:42.568499Z",
     "shell.execute_reply": "2024-02-25T17:08:42.566992Z"
    },
    "papermill": {
     "duration": 3.930057,
     "end_time": "2024-02-25T17:08:42.571717",
     "exception": false,
     "start_time": "2024-02-25T17:08:38.641660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing text file from csv dataset: 100%|â–ˆâ–ˆ| 680/680 [00:01<00:00, 563.09it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python preprocessing_python/text_generator.py \\\n",
    "        --file_path base-ehr-data/base_red3.csv \\\n",
    "        --output_folder /data \\\n",
    "        --create_pretrain_text_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1723f0eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T17:08:42.603415Z",
     "iopub.status.busy": "2024-02-25T17:08:42.603022Z",
     "iopub.status.idle": "2024-02-25T17:08:46.433166Z",
     "shell.execute_reply": "2024-02-25T17:08:46.431986Z"
    },
    "papermill": {
     "duration": 3.848506,
     "end_time": "2024-02-25T17:08:46.435747",
     "exception": false,
     "start_time": "2024-02-25T17:08:42.587241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input file: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680/680 [00:01<00:00, 440.03it/s]\r\n",
      "Creating dataset for finetuning: 11481it [00:00, 150657.02it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python preprocessing_python/text_generator.py \\\n",
    "        --file_path /kaggle/input/base-ehr-data/base_red3.csv \\\n",
    "        --output_folder /data \\\n",
    "        --output_name finetuning_dataset.txt \\\n",
    "        --create_finetuning_text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6deaeb",
   "metadata": {
    "papermill": {
     "duration": 0.015326,
     "end_time": "2024-02-25T17:08:46.466772",
     "exception": false,
     "start_time": "2024-02-25T17:08:46.451446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Both mlm_nsp train and eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c21a41e",
   "metadata": {
    "papermill": {
     "duration": 0.01535,
     "end_time": "2024-02-25T17:08:46.497676",
     "exception": false,
     "start_time": "2024-02-25T17:08:46.482326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Only our pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a60830",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T17:08:46.531728Z",
     "iopub.status.busy": "2024-02-25T17:08:46.530972Z",
     "iopub.status.idle": "2024-02-25T18:29:22.472662Z",
     "shell.execute_reply": "2024-02-25T18:29:22.471571Z"
    },
    "papermill": {
     "duration": 4835.961661,
     "end_time": "2024-02-25T18:29:22.475099",
     "exception": false,
     "start_time": "2024-02-25T17:08:46.513438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 17:08:57.050125: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 17:08:57.050256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 17:08:57.165754: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Output files will be saved in folder: /kaggle/working/output/our_pretrain_only_mlm_nsp\r\n",
      "tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48.0/48.0 [00:00<00:00, 209kB/s]\r\n",
      "vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:00<00:00, 1.40MB/s]\r\n",
      "tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 466k/466k [00:00<00:00, 1.87MB/s]\r\n",
      "config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 570/570 [00:00<00:00, 2.42MB/s]\r\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 440M/440M [00:01<00:00, 345MB/s]\r\n",
      "  0%|                                                   | 0/865 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:35<00:00,  1.50it/s, loss=0.858]\r\n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:36<00:00,  1.50it/s, loss=0.255]\r\n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:38<00:00,  1.50it/s, loss=0.0781]\r\n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:38<00:00,  1.50it/s, loss=0.157]\r\n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:38<00:00,  1.49it/s, loss=0.00927]\r\n",
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:38<00:00,  1.50it/s, loss=0.14]\r\n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:38<00:00,  1.50it/s, loss=0.00222]\r\n",
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [09:38<00:00,  1.50it/s, loss=0.0316]\r\n",
      "Average loss = 0.031576935201883316\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 217/217 [02:58<00:00,  1.22it/s, loss=0.0387]\r\n",
      "Nsp acc: 0.9403330249768732\r\n",
      "Mlm acc: 0.48940998487140697\r\n"
     ]
    }
   ],
   "source": [
    "!python run_pre_train.py \\\n",
    "      --do_eval \\\n",
    "      --do_train \\\n",
    "      --train_batch_size 10 \\\n",
    "      --pre_train_tasks mlm_nsp \\\n",
    "      --num_epochs 8 \\\n",
    "      --input_file /data/dataset_text.txt \\\n",
    "      --output_dir /output/our_pretrain_only_mlm_nsp \\\n",
    "      --use_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22106788",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:29:24.493940Z",
     "iopub.status.busy": "2024-02-25T18:29:24.493559Z",
     "iopub.status.idle": "2024-02-25T18:38:42.749805Z",
     "shell.execute_reply": "2024-02-25T18:38:42.748700Z"
    },
    "papermill": {
     "duration": 559.225955,
     "end_time": "2024-02-25T18:38:42.751983",
     "exception": false,
     "start_time": "2024-02-25T18:29:23.526028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 18:29:30.040896: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 18:29:30.040952: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 18:29:30.042445: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Output files will be saved in folder: /kaggle/working/output/our_pretrain_only_mlm_nsp\r\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/working/output/our_pretrain_only_mlm_nsp/pre_trained_model and are newly initialized: ['classifier.weight', 'classifier.bias']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "/kaggle/working/bert_medical_records/load_dataset.py:35: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3614.)\r\n",
      "  inputs['labels'] = torch.LongTensor(labels).T\r\n",
      "len(train_dataset) = 9185\r\n",
      "len(test_dataset) = 2296\r\n",
      "  0%|                                                   | 0/919 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 919/919 [08:16<00:00,  1.85it/s, loss=0.265]\r\n",
      "Average loss = 0.26538699865341187\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:41<00:00,  5.56it/s, loss=56.5]\r\n",
      "1992\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:37: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:31: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "result = {'acc': 0.867595818815331, 'f1': 0.8959616700889801, 'acc_and_f1': 0.8817787444521555}\r\n"
     ]
    }
   ],
   "source": [
    "!python run_glue.py \\\n",
    "      --do_train \\\n",
    "      --do_eval \\\n",
    "      --train_batch_size 10 \\\n",
    "      --num_epochs 1 \\\n",
    "      --model_input /output/our_pretrain_only_mlm_nsp \\\n",
    "      --input_file /data/finetuning_dataset.txt \\\n",
    "      --output_dir /output/our_pretrain_only_mlm_nsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393473f4",
   "metadata": {
    "papermill": {
     "duration": 1.178471,
     "end_time": "2024-02-25T18:38:45.121341",
     "exception": false,
     "start_time": "2024-02-25T18:38:43.942870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bert pretrained without further pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61488011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:38:47.386051Z",
     "iopub.status.busy": "2024-02-25T18:38:47.385656Z",
     "iopub.status.idle": "2024-02-25T18:42:05.022601Z",
     "shell.execute_reply": "2024-02-25T18:42:05.021464Z"
    },
    "papermill": {
     "duration": 198.755952,
     "end_time": "2024-02-25T18:42:05.025024",
     "exception": false,
     "start_time": "2024-02-25T18:38:46.269072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 18:38:52.780445: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 18:38:52.780501: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 18:38:52.781933: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Evaluating:   0%|                                       | 0/217 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 217/217 [02:58<00:00,  1.21it/s, loss=20.4]\r\n",
      "Nsp acc: 0.5064754856614246\r\n",
      "Mlm acc: 0.2629858336360334\r\n"
     ]
    }
   ],
   "source": [
    "!python run_pre_train.py \\\n",
    "      --do_eval \\\n",
    "      --train_batch_size 10 \\\n",
    "      --pre_train_tasks mlm_nsp \\\n",
    "      --input_file /data/dataset_text.txt \\\n",
    "      --use_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb303218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:42:07.378934Z",
     "iopub.status.busy": "2024-02-25T18:42:07.378061Z",
     "iopub.status.idle": "2024-02-25T18:51:25.393621Z",
     "shell.execute_reply": "2024-02-25T18:51:25.392528Z"
    },
    "papermill": {
     "duration": 559.17994,
     "end_time": "2024-02-25T18:51:25.395963",
     "exception": false,
     "start_time": "2024-02-25T18:42:06.216023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 18:42:12.755189: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 18:42:12.755243: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 18:42:12.756695: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Output files will be saved in folder: /kaggle/working/output/just_bert_mlm_nsp\r\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "/kaggle/working/bert_medical_records/load_dataset.py:35: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3614.)\r\n",
      "  inputs['labels'] = torch.LongTensor(labels).T\r\n",
      "len(train_dataset) = 9185\r\n",
      "len(test_dataset) = 2296\r\n",
      "  0%|                                                   | 0/919 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 919/919 [08:16<00:00,  1.85it/s, loss=0.36]\r\n",
      "Average loss = 0.36049866676330566\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:41<00:00,  5.56it/s, loss=59.2]\r\n",
      "1989\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:37: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:31: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "result = {'acc': 0.8662891986062717, 'f1': 0.9002923026956805, 'acc_and_f1': 0.8832907506509762}\r\n"
     ]
    }
   ],
   "source": [
    "!python run_glue.py \\\n",
    "      --do_train \\\n",
    "      --do_eval \\\n",
    "      --train_batch_size 10 \\\n",
    "      --num_epochs 1 \\\n",
    "      --input_file /data/finetuning_dataset.txt \\\n",
    "      --output_dir /output/just_bert_mlm_nsp \\\n",
    "      --use_pretrained_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f95d4fd",
   "metadata": {
    "papermill": {
     "duration": 1.330715,
     "end_time": "2024-02-25T18:51:28.001075",
     "exception": false,
     "start_time": "2024-02-25T18:51:26.670360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bert pretrained with our pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6960a40d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:51:30.629626Z",
     "iopub.status.busy": "2024-02-25T18:51:30.628982Z",
     "iopub.status.idle": "2024-02-25T18:56:44.356890Z",
     "shell.execute_reply": "2024-02-25T18:56:44.355786Z"
    },
    "papermill": {
     "duration": 315.012365,
     "end_time": "2024-02-25T18:56:44.359177",
     "exception": false,
     "start_time": "2024-02-25T18:51:29.346812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 18:51:36.117446: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 18:51:36.117508: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 18:51:36.118994: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Output files will be saved in folder: /kaggle/working/output/bert_mlm_nsp_with_pretrain\r\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight']\r\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.51it/s, loss=0.107]\r\n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.0563]\r\n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.0111]\r\n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.00926]\r\n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.00558]\r\n",
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.0049]\r\n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.00326]\r\n",
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.00267]\r\n",
      "Average loss = 0.002674547955393791\r\n",
      "Evaluating:   0%|                                        | 0/14 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:10<00:00,  1.28it/s, loss=0.00577]\r\n",
      "Mlm acc: 0.9668117519042437\r\n"
     ]
    }
   ],
   "source": [
    "!python run_pre_train.py \\\n",
    "      --do_eval \\\n",
    "      --do_train \\\n",
    "      --train_batch_size 10 \\\n",
    "      --pre_train_tasks mlm \\\n",
    "      --num_epochs 8 \\\n",
    "      --input_file /data/dataset_text.txt \\\n",
    "      --output_dir /output/bert_mlm_nsp_with_pretrain \\\n",
    "      --use_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d87c84a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:56:47.104567Z",
     "iopub.status.busy": "2024-02-25T18:56:47.103594Z",
     "iopub.status.idle": "2024-02-25T19:06:05.606736Z",
     "shell.execute_reply": "2024-02-25T19:06:05.605584Z"
    },
    "papermill": {
     "duration": 559.843697,
     "end_time": "2024-02-25T19:06:05.609014",
     "exception": false,
     "start_time": "2024-02-25T18:56:45.765317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 18:56:52.571502: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 18:56:52.571562: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 18:56:52.573135: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Output files will be saved in folder: /kaggle/working/output/bert_mlm_nsp_with_pretrain\r\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/working/output/bert_mlm_nsp_with_pretrain/pre_trained_model and are newly initialized: ['classifier.weight', 'bert.pooler.dense.weight', 'classifier.bias', 'bert.pooler.dense.bias']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "/kaggle/working/bert_medical_records/load_dataset.py:35: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3614.)\r\n",
      "  inputs['labels'] = torch.LongTensor(labels).T\r\n",
      "len(train_dataset) = 9185\r\n",
      "len(test_dataset) = 2296\r\n",
      "  0%|                                                   | 0/919 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 919/919 [08:16<00:00,  1.85it/s, loss=0.186]\r\n",
      "Average loss = 0.18634262681007385\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:41<00:00,  5.55it/s, loss=63.2]\r\n",
      "1991\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:37: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:31: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "result = {'acc': 0.8671602787456446, 'f1': 0.8967152048763968, 'acc_and_f1': 0.8819377418110207}\r\n"
     ]
    }
   ],
   "source": [
    "!python run_glue.py \\\n",
    "      --do_train \\\n",
    "      --do_eval \\\n",
    "      --train_batch_size 10 \\\n",
    "      --num_epochs 1 \\\n",
    "      --model_input /output/bert_mlm_nsp_with_pretrain \\\n",
    "      --input_file /data/finetuning_dataset.txt \\\n",
    "      --output_dir /output/bert_mlm_nsp_with_pretrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092af782",
   "metadata": {
    "papermill": {
     "duration": 1.54712,
     "end_time": "2024-02-25T19:06:08.643500",
     "exception": false,
     "start_time": "2024-02-25T19:06:07.096380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Only mlm pretrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594b7fe3",
   "metadata": {
    "papermill": {
     "duration": 1.545231,
     "end_time": "2024-02-25T19:06:11.757364",
     "exception": false,
     "start_time": "2024-02-25T19:06:10.212133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Only our pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0bf3a02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T19:06:14.896122Z",
     "iopub.status.busy": "2024-02-25T19:06:14.895327Z",
     "iopub.status.idle": "2024-02-25T19:11:28.343441Z",
     "shell.execute_reply": "2024-02-25T19:11:28.342445Z"
    },
    "papermill": {
     "duration": 315.01316,
     "end_time": "2024-02-25T19:11:28.345823",
     "exception": false,
     "start_time": "2024-02-25T19:06:13.332663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 19:06:20.334776: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 19:06:20.334834: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 19:06:20.336348: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Output files will be saved in folder: /kaggle/working/output/our_pretrain_only_mlm\r\n",
      "Train the tokenizer\r\n",
      "\u001b[2K[00:00:00] Tokenize words                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 854      /      854\r\n",
      "\u001b[2K[00:00:00] Count pairs                    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 854      /      854\r\n",
      "\u001b[2K[00:00:00] Compute merges                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1248     /     1248\r\n",
      "Saving the tokenizer\r\n",
      "Loading the workable tokenizer\r\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.51it/s, loss=6.76]\r\n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=3.08]\r\n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=1.03]\r\n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.406]\r\n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.311]\r\n",
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.128]\r\n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.0723]\r\n",
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.27]\r\n",
      "Average loss = 0.2699395418167114\r\n",
      "Evaluating:   0%|                                        | 0/14 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:10<00:00,  1.31it/s, loss=0.109]\r\n",
      "Mlm acc: 0.12939841089670828\r\n"
     ]
    }
   ],
   "source": [
    "!python run_pre_train.py \\\n",
    "      --do_eval \\\n",
    "      --do_train \\\n",
    "      --train_batch_size 10 \\\n",
    "      --pre_train_tasks mlm \\\n",
    "      --num_epochs 8 \\\n",
    "      --input_file /data/dataset_text.txt \\\n",
    "      --output_dir /output/our_pretrain_only_mlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45458add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T19:11:31.598294Z",
     "iopub.status.busy": "2024-02-25T19:11:31.597508Z",
     "iopub.status.idle": "2024-02-25T19:20:50.212910Z",
     "shell.execute_reply": "2024-02-25T19:20:50.211910Z"
    },
    "papermill": {
     "duration": 560.244945,
     "end_time": "2024-02-25T19:20:50.215250",
     "exception": false,
     "start_time": "2024-02-25T19:11:29.970305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 19:11:37.187614: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 19:11:37.187672: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 19:11:37.189258: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Output files will be saved in folder: /kaggle/working/output/our_pretrain_only_mlm\r\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/working/output/our_pretrain_only_mlm/pre_trained_model and are newly initialized: ['classifier.bias', 'classifier.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "/kaggle/working/bert_medical_records/load_dataset.py:35: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3614.)\r\n",
      "  inputs['labels'] = torch.LongTensor(labels).T\r\n",
      "len(train_dataset) = 9185\r\n",
      "len(test_dataset) = 2296\r\n",
      "  0%|                                                   | 0/919 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 919/919 [08:16<00:00,  1.85it/s, loss=0.186]\r\n",
      "Average loss = 0.18591377139091492\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:41<00:00,  5.55it/s, loss=92.9]\r\n",
      "1965\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:37: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:31: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "result = {'acc': 0.855836236933798, 'f1': 0.9009871373018247, 'acc_and_f1': 0.8784116871178114}\r\n"
     ]
    }
   ],
   "source": [
    "!python run_glue.py \\\n",
    "      --do_train \\\n",
    "      --do_eval \\\n",
    "      --train_batch_size 10 \\\n",
    "      --num_epochs 1 \\\n",
    "      --model_input /output/our_pretrain_only_mlm \\\n",
    "      --input_file /data/finetuning_dataset.txt \\\n",
    "      --output_dir /output/our_pretrain_only_mlm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25d4368",
   "metadata": {
    "papermill": {
     "duration": 1.813852,
     "end_time": "2024-02-25T19:20:53.807626",
     "exception": false,
     "start_time": "2024-02-25T19:20:51.993774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bert pretrained without further pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29f0b0ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T19:20:57.304591Z",
     "iopub.status.busy": "2024-02-25T19:20:57.304213Z",
     "iopub.status.idle": "2024-02-25T19:21:21.010911Z",
     "shell.execute_reply": "2024-02-25T19:21:21.009744Z"
    },
    "papermill": {
     "duration": 25.477409,
     "end_time": "2024-02-25T19:21:21.013441",
     "exception": false,
     "start_time": "2024-02-25T19:20:55.536032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 19:21:02.799267: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 19:21:02.799317: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 19:21:02.800865: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias']\r\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "Evaluating:   0%|                                        | 0/14 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:11<00:00,  1.23it/s, loss=12.5]\r\n",
      "Mlm acc: 0.5784966698382493\r\n"
     ]
    }
   ],
   "source": [
    "!python run_pre_train.py \\\n",
    "      --do_eval \\\n",
    "      --train_batch_size 10 \\\n",
    "      --pre_train_tasks mlm \\\n",
    "      --input_file /data/dataset_text.txt \\\n",
    "      --use_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a619397a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T19:21:24.498877Z",
     "iopub.status.busy": "2024-02-25T19:21:24.497977Z",
     "iopub.status.idle": "2024-02-25T19:30:42.677751Z",
     "shell.execute_reply": "2024-02-25T19:30:42.676647Z"
    },
    "papermill": {
     "duration": 559.889955,
     "end_time": "2024-02-25T19:30:42.680081",
     "exception": false,
     "start_time": "2024-02-25T19:21:22.790126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 19:21:29.921874: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 19:21:29.921932: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 19:21:29.923391: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Output files will be saved in folder: /kaggle/working/output/just_bert_mlm_only\r\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "/kaggle/working/bert_medical_records/load_dataset.py:35: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3614.)\r\n",
      "  inputs['labels'] = torch.LongTensor(labels).T\r\n",
      "len(train_dataset) = 9185\r\n",
      "len(test_dataset) = 2296\r\n",
      "  0%|                                                   | 0/919 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 919/919 [08:16<00:00,  1.85it/s, loss=0.124]\r\n",
      "Average loss = 0.12413150072097778\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:41<00:00,  5.56it/s, loss=59.3]\r\n",
      "1961\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:37: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:31: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "result = {'acc': 0.8540940766550522, 'f1': 0.9049105875674142, 'acc_and_f1': 0.8795023321112332}\r\n"
     ]
    }
   ],
   "source": [
    "!python run_glue.py \\\n",
    "      --do_train \\\n",
    "      --do_eval \\\n",
    "      --train_batch_size 10 \\\n",
    "      --num_epochs 1 \\\n",
    "      --input_file /data/finetuning_dataset.txt \\\n",
    "      --output_dir /output/just_bert_mlm_only \\\n",
    "      --use_pretrained_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f2cc2",
   "metadata": {
    "papermill": {
     "duration": 1.954524,
     "end_time": "2024-02-25T19:30:46.576745",
     "exception": false,
     "start_time": "2024-02-25T19:30:44.622221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bert pretrained with our pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26aa7824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T19:30:50.335575Z",
     "iopub.status.busy": "2024-02-25T19:30:50.334635Z",
     "iopub.status.idle": "2024-02-25T19:36:04.227131Z",
     "shell.execute_reply": "2024-02-25T19:36:04.225967Z"
    },
    "papermill": {
     "duration": 315.815381,
     "end_time": "2024-02-25T19:36:04.229448",
     "exception": false,
     "start_time": "2024-02-25T19:30:48.414067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 19:30:55.807048: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 19:30:55.807115: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 19:30:55.808624: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Output files will be saved in folder: /kaggle/working/output/bert_only_mlm_with_pretrain\r\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias']\r\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.51it/s, loss=0.131]\r\n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.0345]\r\n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.0101]\r\n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.0153]\r\n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.0059]\r\n",
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.016]\r\n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.00291]\r\n",
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:36<00:00,  1.52it/s, loss=0.00466]\r\n",
      "Average loss = 0.004664451349526644\r\n",
      "Evaluating:   0%|                                        | 0/14 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:10<00:00,  1.27it/s, loss=0.00775]\r\n",
      "Mlm acc: 0.9785915492957746\r\n"
     ]
    }
   ],
   "source": [
    "!python run_pre_train.py \\\n",
    "      --do_eval \\\n",
    "      --do_train \\\n",
    "      --train_batch_size 10 \\\n",
    "      --pre_train_tasks mlm \\\n",
    "      --num_epochs 8 \\\n",
    "      --input_file /data/dataset_text.txt \\\n",
    "      --output_dir /output/bert_only_mlm_with_pretrain \\\n",
    "      --use_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5ee5431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T19:36:08.206423Z",
     "iopub.status.busy": "2024-02-25T19:36:08.206029Z",
     "iopub.status.idle": "2024-02-25T19:45:26.100697Z",
     "shell.execute_reply": "2024-02-25T19:45:26.099698Z"
    },
    "papermill": {
     "duration": 559.879022,
     "end_time": "2024-02-25T19:45:26.102953",
     "exception": false,
     "start_time": "2024-02-25T19:36:06.223931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 19:36:13.637269: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 19:36:13.637326: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 19:36:13.638810: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Output files will be saved in folder: /kaggle/working/output/bert_only_mlm_with_pretrain\r\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/working/output/bert_only_mlm_with_pretrain/pre_trained_model and are newly initialized: ['classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "/kaggle/working/bert_medical_records/load_dataset.py:35: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3614.)\r\n",
      "  inputs['labels'] = torch.LongTensor(labels).T\r\n",
      "len(train_dataset) = 9185\r\n",
      "len(test_dataset) = 2296\r\n",
      "  0%|                                                   | 0/919 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 919/919 [08:16<00:00,  1.85it/s, loss=0.326]\r\n",
      "Average loss = 0.32642191648483276\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:41<00:00,  5.56it/s, loss=66.4]\r\n",
      "1967\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:37: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:31: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "result = {'acc': 0.8567073170731707, 'f1': 0.8859618717504333, 'acc_and_f1': 0.871334594411802}\r\n"
     ]
    }
   ],
   "source": [
    "!python run_glue.py \\\n",
    "      --do_train \\\n",
    "      --do_eval \\\n",
    "      --train_batch_size 10 \\\n",
    "      --num_epochs 1 \\\n",
    "      --model_input /output/bert_only_mlm_with_pretrain \\\n",
    "      --input_file /data/finetuning_dataset.txt \\\n",
    "      --output_dir /output/bert_only_mlm_with_pretrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8fd8ee",
   "metadata": {
    "papermill": {
     "duration": 2.031291,
     "end_time": "2024-02-25T19:45:30.255824",
     "exception": false,
     "start_time": "2024-02-25T19:45:28.224533",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Only NSP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4636680b",
   "metadata": {
    "papermill": {
     "duration": 2.129898,
     "end_time": "2024-02-25T19:45:34.520785",
     "exception": false,
     "start_time": "2024-02-25T19:45:32.390887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Only our pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "503add2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T19:45:38.689282Z",
     "iopub.status.busy": "2024-02-25T19:45:38.688866Z",
     "iopub.status.idle": "2024-02-25T20:48:59.875786Z",
     "shell.execute_reply": "2024-02-25T20:48:59.874705Z"
    },
    "papermill": {
     "duration": 3803.223384,
     "end_time": "2024-02-25T20:48:59.878017",
     "exception": false,
     "start_time": "2024-02-25T19:45:36.654633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 19:45:44.154815: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 19:45:44.154872: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 19:45:44.156380: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Output files will be saved in folder: /kaggle/working/output/our_pretrain_only_nsp\r\n",
      "Train the tokenizer\r\n",
      "\u001b[2K[00:00:00] Tokenize words                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 854      /      854\r\n",
      "\u001b[2K[00:00:00] Count pairs                    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 854      /      854\r\n",
      "\u001b[2K[00:00:00] Compute merges                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1248     /     1248\r\n",
      "Saving the tokenizer\r\n",
      "Loading the workable tokenizer\r\n",
      "  0%|                                                   | 0/865 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1470: FutureWarning: The `next_sentence_label` argument is deprecated and will be removed in a future version, use `labels` instead.\r\n",
      "  warnings.warn(\r\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:48<00:00,  1.85it/s, loss=0.695]\r\n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:47<00:00,  1.85it/s, loss=0.724]\r\n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:47<00:00,  1.85it/s, loss=0.691]\r\n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:47<00:00,  1.85it/s, loss=0.708]\r\n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:47<00:00,  1.85it/s, loss=0.71]\r\n",
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:47<00:00,  1.85it/s, loss=0.687]\r\n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:47<00:00,  1.85it/s, loss=0.698]\r\n",
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:47<00:00,  1.85it/s, loss=0.718]\r\n",
      "Average loss = 0.7177965641021729\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 217/217 [00:39<00:00,  5.51it/s, loss=0.646]\r\n",
      "Nsp acc: 0.5018501387604071\r\n"
     ]
    }
   ],
   "source": [
    "!python run_pre_train.py \\\n",
    "      --do_eval \\\n",
    "      --do_train \\\n",
    "      --train_batch_size 10 \\\n",
    "      --pre_train_tasks nsp \\\n",
    "      --num_epochs 8 \\\n",
    "      --input_file /data/dataset_text.txt \\\n",
    "      --output_dir /output/our_pretrain_only_nsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd420794",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T20:49:06.102498Z",
     "iopub.status.busy": "2024-02-25T20:49:06.102075Z",
     "iopub.status.idle": "2024-02-25T20:58:24.016420Z",
     "shell.execute_reply": "2024-02-25T20:58:24.015279Z"
    },
    "papermill": {
     "duration": 561.00323,
     "end_time": "2024-02-25T20:58:24.018867",
     "exception": false,
     "start_time": "2024-02-25T20:49:03.015637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 20:49:11.520927: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 20:49:11.520985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 20:49:11.522490: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Output files will be saved in folder: /kaggle/working/output/our_pretrain_only_nsp\r\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/working/output/our_pretrain_only_nsp/pre_trained_model and are newly initialized: ['classifier.weight', 'classifier.bias']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "/kaggle/working/bert_medical_records/load_dataset.py:35: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3614.)\r\n",
      "  inputs['labels'] = torch.LongTensor(labels).T\r\n",
      "len(train_dataset) = 9185\r\n",
      "len(test_dataset) = 2296\r\n",
      "  0%|                                                   | 0/919 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 919/919 [08:16<00:00,  1.85it/s, loss=0.639]\r\n",
      "Average loss = 0.6391339898109436\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:41<00:00,  5.55it/s, loss=149]\r\n",
      "1560\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:37: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:31: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "result = {'acc': 0.6794425087108014, 'f1': 0.8091286307053942, 'acc_and_f1': 0.7442855697080978}\r\n"
     ]
    }
   ],
   "source": [
    "!python run_glue.py \\\n",
    "      --do_train \\\n",
    "      --do_eval \\\n",
    "      --train_batch_size 10 \\\n",
    "      --num_epochs 1 \\\n",
    "      --model_input /output/our_pretrain_only_nsp \\\n",
    "      --input_file /data/finetuning_dataset.txt \\\n",
    "      --output_dir /output/our_pretrain_only_nsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e13d39c",
   "metadata": {
    "papermill": {
     "duration": 3.24336,
     "end_time": "2024-02-25T20:58:30.391516",
     "exception": false,
     "start_time": "2024-02-25T20:58:27.148156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bert pretrained with no further pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e646ad87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T20:58:36.917554Z",
     "iopub.status.busy": "2024-02-25T20:58:36.916795Z",
     "iopub.status.idle": "2024-02-25T20:59:34.618581Z",
     "shell.execute_reply": "2024-02-25T20:59:34.617601Z"
    },
    "papermill": {
     "duration": 60.819928,
     "end_time": "2024-02-25T20:59:34.621025",
     "exception": false,
     "start_time": "2024-02-25T20:58:33.801097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 20:58:42.447573: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 20:58:42.447647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 20:58:42.449060: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Evaluating:   0%|                                       | 0/217 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1470: FutureWarning: The `next_sentence_label` argument is deprecated and will be removed in a future version, use `labels` instead.\r\n",
      "  warnings.warn(\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 217/217 [00:39<00:00,  5.48it/s, loss=6.15]\r\n",
      "Nsp acc: 0.5198889916743756\r\n"
     ]
    }
   ],
   "source": [
    "!python run_pre_train.py \\\n",
    "      --do_eval \\\n",
    "      --train_batch_size 10 \\\n",
    "      --pre_train_tasks nsp \\\n",
    "      --input_file /data/dataset_text.txt \\\n",
    "      --use_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c9b1f8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T20:59:41.308022Z",
     "iopub.status.busy": "2024-02-25T20:59:41.307650Z",
     "iopub.status.idle": "2024-02-25T21:08:59.926663Z",
     "shell.execute_reply": "2024-02-25T21:08:59.925660Z"
    },
    "papermill": {
     "duration": 562.062712,
     "end_time": "2024-02-25T21:08:59.928963",
     "exception": false,
     "start_time": "2024-02-25T20:59:37.866251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 20:59:46.772285: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 20:59:46.772343: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 20:59:46.773732: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Output files will be saved in folder: /kaggle/working/output/just_bert_only_nsp\r\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "/kaggle/working/bert_medical_records/load_dataset.py:35: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3614.)\r\n",
      "  inputs['labels'] = torch.LongTensor(labels).T\r\n",
      "len(train_dataset) = 9185\r\n",
      "len(test_dataset) = 2296\r\n",
      "  0%|                                                   | 0/919 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 919/919 [08:16<00:00,  1.85it/s, loss=0.336]\r\n",
      "Average loss = 0.3360660970211029\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:41<00:00,  5.55it/s, loss=62.2]\r\n",
      "2020\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:37: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:31: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "result = {'acc': 0.8797909407665505, 'f1': 0.9091507570770244, 'acc_and_f1': 0.8944708489217874}\r\n"
     ]
    }
   ],
   "source": [
    "!python run_glue.py \\\n",
    "      --do_train \\\n",
    "      --do_eval \\\n",
    "      --train_batch_size 10 \\\n",
    "      --num_epochs 1 \\\n",
    "      --input_file /data/finetuning_dataset.txt \\\n",
    "      --output_dir /output/just_bert_only_nsp \\\n",
    "      --use_pretrained_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24ede3",
   "metadata": {
    "papermill": {
     "duration": 3.28993,
     "end_time": "2024-02-25T21:09:06.774249",
     "exception": false,
     "start_time": "2024-02-25T21:09:03.484319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bert pretrained with our pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2f5666e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T21:09:13.640924Z",
     "iopub.status.busy": "2024-02-25T21:09:13.640514Z",
     "iopub.status.idle": "2024-02-25T22:12:35.029452Z",
     "shell.execute_reply": "2024-02-25T22:12:35.028456Z"
    },
    "papermill": {
     "duration": 3804.701345,
     "end_time": "2024-02-25T22:12:35.031852",
     "exception": false,
     "start_time": "2024-02-25T21:09:10.330507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 21:09:19.101021: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 21:09:19.101083: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 21:09:19.102560: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Output files will be saved in folder: /kaggle/working/output/bert_nsp_with_pretrain\r\n",
      "Train the tokenizer\r\n",
      "\u001b[2K[00:00:00] Tokenize words                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 854      /      854\r\n",
      "\u001b[2K[00:00:00] Count pairs                    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 854      /      854\r\n",
      "\u001b[2K[00:00:00] Compute merges                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1248     /     1248\r\n",
      "Saving the tokenizer\r\n",
      "Loading the workable tokenizer\r\n",
      "  0%|                                                   | 0/865 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1470: FutureWarning: The `next_sentence_label` argument is deprecated and will be removed in a future version, use `labels` instead.\r\n",
      "  warnings.warn(\r\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:48<00:00,  1.85it/s, loss=0.686]\r\n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:47<00:00,  1.85it/s, loss=0.861]\r\n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:47<00:00,  1.85it/s, loss=0.682]\r\n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:47<00:00,  1.85it/s, loss=0.706]\r\n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:47<00:00,  1.85it/s, loss=0.67]\r\n",
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:47<00:00,  1.85it/s, loss=0.689]\r\n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:47<00:00,  1.85it/s, loss=0.693]\r\n",
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 865/865 [07:47<00:00,  1.85it/s, loss=0.634]\r\n",
      "Average loss = 0.6340930461883545\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 217/217 [00:39<00:00,  5.51it/s, loss=0.701]\r\n",
      "Nsp acc: 0.4935245143385754\r\n"
     ]
    }
   ],
   "source": [
    "!python run_pre_train.py \\\n",
    "      --do_eval \\\n",
    "      --do_train \\\n",
    "      --train_batch_size 10 \\\n",
    "      --pre_train_tasks nsp \\\n",
    "      --num_epochs 8 \\\n",
    "      --input_file /data/dataset_text.txt \\\n",
    "      --output_dir /output/bert_nsp_with_pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c61f7ec2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T22:12:43.851644Z",
     "iopub.status.busy": "2024-02-25T22:12:43.851265Z",
     "iopub.status.idle": "2024-02-25T22:22:01.828350Z",
     "shell.execute_reply": "2024-02-25T22:22:01.827241Z"
    },
    "papermill": {
     "duration": 562.411663,
     "end_time": "2024-02-25T22:22:01.830765",
     "exception": false,
     "start_time": "2024-02-25T22:12:39.419102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-25 22:12:49.279823: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-25 22:12:49.279881: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-25 22:12:49.281396: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Output files will be saved in folder: /kaggle/working/output/bert_nsp_with_pretrain\r\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/working/output/bert_nsp_with_pretrain/pre_trained_model and are newly initialized: ['classifier.weight', 'classifier.bias']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "/kaggle/working/bert_medical_records/load_dataset.py:35: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3614.)\r\n",
      "  inputs['labels'] = torch.LongTensor(labels).T\r\n",
      "len(train_dataset) = 9185\r\n",
      "len(test_dataset) = 2296\r\n",
      "  0%|                                                   | 0/919 [00:00<?, ?it/s]/kaggle/working/bert_medical_records/load_dataset.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.inputs.items()}\r\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 919/919 [08:16<00:00,  1.85it/s, loss=0.533]\r\n",
      "Average loss = 0.5332876443862915\r\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [00:41<00:00,  5.55it/s, loss=146]\r\n",
      "1555\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:37: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/data/metrics/__init__.py:31: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Evaluate library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\r\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\r\n",
      "result = {'acc': 0.6772648083623694, 'f1': 0.8075824461178914, 'acc_and_f1': 0.7424236272401303}\r\n"
     ]
    }
   ],
   "source": [
    "!python run_glue.py \\\n",
    "      --do_train \\\n",
    "      --do_eval \\\n",
    "      --train_batch_size 10 \\\n",
    "      --num_epochs 1 \\\n",
    "      --model_input /output/bert_nsp_with_pretrain \\\n",
    "      --input_file /data/finetuning_dataset.txt \\\n",
    "      --output_dir /output/bert_nsp_with_pretrain"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4012665,
     "sourceId": 6982185,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4466132,
     "sourceId": 7659768,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4490406,
     "sourceId": 7693946,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19242.187597,
   "end_time": "2024-02-25T22:28:36.910492",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-25T17:07:54.722895",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
